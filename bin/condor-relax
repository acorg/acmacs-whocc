#! /usr/bin/env python3

"""
Relaxes a chart using htcondor
"""

import sys, os, logging, datetime, time
from pathlib import Path

now = datetime.datetime.now().strftime("%Y-%m%d-%H%M%S")
real_cwd = os.path.realpath(os.getcwd())

# ----------------------------------------------------------------------

def main():
    import traceback
    try:
        args = parse_args()
        source = os.path.realpath(args.source[0]) # before chdir in make_working_dir
        working_dir = make_working_dir(args)
        condor_relax_grid(args, source=source, working_dir=working_dir)
        output = combine_results(source=source, working_dir=working_dir, minimum_column_basis=args.minimum_column_basis, keep_projections=args.keep_projections)
        if args.keep_intermediate:
            print(f"working dir: {working_dir}")
        else:
            import shutil
            shutil.rmtree(working_dir)
        print(output)
        print(f"syget -p {os.path.basename(output)}")
        return 0
    except Exception as err:
        logging.error('{}\n{}'.format(err, traceback.format_exc()))
        return 1

# ----------------------------------------------------------------------

def parse_args():
    import argparse
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-p', '--priority', action='store', dest='priority', type=int, default=0, help='condor priority.')
    parser.add_argument('-n', action='store', dest='number_of_optimizations', type=int, default=1000, help='number of optimizations.')
    parser.add_argument('-d', action='store', dest='number_of_dimensions', type=int, default=2, help='number of dimensions.')
    parser.add_argument('-m', action='store', dest='minimum_column_basis', default="none", help='minimum column basis.')
    parser.add_argument('-k', "--keep-projections", action='store', dest='keep_projections', type=int, default=10, help='number of the best projections to keep.')
    parser.add_argument('-t', "--threads", action='store', dest='threads', type=int, default=32, help='number of threads in the chart-relax.')
    parser.add_argument("--keep-intermediate", action='store_true', dest='keep_intermediate', default=False, help='keep intermediate files.')

    parser.add_argument("source", nargs=1)

    args = parser.parse_args()
    logging.basicConfig(level=logging.DEBUG, format="%(levelname)s %(asctime)s: %(message)s")

    if not args.source[0].endswith(".ace"):
        raise RuntimeError(f"Source must be an ace file (got: {source[0]})")

    return args

# ======================================================================

def condor_relax_grid(args, source, working_dir):
    chunk_size = min(args.number_of_optimizations, 1000)
    number_of_copies = args.number_of_optimizations // chunk_size + (1 if (args.number_of_optimizations % chunk_size) != 0 else 0)
    condor_submit("chart-relax-grid",
                  [
                      "-m", args.minimum_column_basis,
                      "-d", args.number_of_dimensions,
                      "-n", chunk_size,
                      "--threads", args.threads,
                      "--keep-projections", args.keep_projections,
                      source,
                  ],
                  output_prefix=f"{os.path.splitext(os.path.basename(source))[0]}.output",
                  threads=args.threads, number_of_copies=number_of_copies, working_dir=working_dir, priority=args.priority)

# ----------------------------------------------------------------------

def combine_results(source, working_dir, minimum_column_basis, keep_projections):
    import subprocess
    output = f"{os.path.splitext(source)[0]}.{minimum_column_basis}-relaxed.ace"
    backup_file(output)
    subprocess.check_call(f"chart-combine-projections {working_dir}/*.output.*.ace -k {keep_projections} -o {output}", shell=True)
    return output

# ----------------------------------------------------------------------

def backup_file(filename):
    if Path(filename).exists():
        name, ext = os.path.splitext(filename)
        infix = time.strftime("%Y-%m%d-%H%M%S", time.localtime(os.stat(filename).st_mtime))
        try:
            os.rename(filename, f"{name}.{infix}{ext}")
        except Exception as err:
            logging.warning('Cannot create backup copy of {}: {}'.format(filename, err), exc_info=True)

# ----------------------------------------------------------------------

def make_working_dir(args):
    global now
    working_dir = Path(real_cwd, f"output.{Path(args.source[0]).stem}.{now}")
    if working_dir.exists():
        time.sleep(1)
        now = datetime.datetime.now().strftime("%Y-%m%d-%H%M%S")
        working_dir = Path(real_cwd, f"{Path(args.source[0]).stem}.{now}")
    working_dir.mkdir()
    os.chdir(working_dir)
    return working_dir

# ----------------------------------------------------------------------

sCondorDesc = """\
universe = vanilla
executable = {executable}
environment = ACMACSD_ROOT=/syn/eu/AD
priority = {priority}
should_transfer_files = NO
notify_user = eu
notification = Error
requirements = (machine == "o16" || machine == "o17" || machine == "i18" || machine == "i19" || machine == "i20" || machine == "i21" || machine == "i22")
request_cpus = {threads}
initialdir = {initialdir}
log = {log_file}
description = {executable_basename} {pwd_basename}

{queue}
"""

sQueue = """\
arguments = "{arguments} '{output}'"
error = stderr.{copy_no:04d}
output = stdout.{copy_no:04d}
queue
"""

def make_queue(copy_no, arguments, output_prefix):
    queue_parameters = {
        "arguments": "'" + "' '".join(str(arg) for arg in arguments) + "'",
        "output": f"{output_prefix}.{copy_no:04d}.ace",
        "copy_no": copy_no
        }
    return sQueue.format(**queue_parameters)

def condor_submit(executable, arguments, output_prefix, threads, number_of_copies, working_dir, priority):
    import subprocess, distutils.spawn
    working_dir.chmod(0o777)
    executable_real = os.path.realpath(distutils.spawn.find_executable(executable))
    parameters = {
        "executable": executable_real,
        "priority": priority,
        "threads": threads,
        "initialdir": str(working_dir),
        "executable_basename": os.path.basename(executable_real),
        "pwd_basename": working_dir.name,
        "log_file": str(working_dir.joinpath("condor.log")),
        "queue": "\n".join(make_queue(copy, arguments=arguments, output_prefix=output_prefix) for copy in range(number_of_copies))
    }

    condor_submit_file = f"condor.submit"
    with open(condor_submit_file, "w") as csf:
        csf.write(sCondorDesc.format(**parameters))

    subprocess.check_call(["condor_submit", condor_submit_file])
    start = datetime.datetime.now()
    print("\n\nwaiting for all jobs to complete\n\n")
    subprocess.check_call(["condor_wait", parameters["log_file"], "-status"]) # , "-echo"
    print(f"\n\ntime of jobs: {datetime.datetime.now() - start}\n\n")

# ----------------------------------------------------------------------
# ======================================================================

exit(main())

# ======================================================================
### Local Variables:
### eval: (if (fboundp 'eu-rename-buffer) (eu-rename-buffer))
### End:
