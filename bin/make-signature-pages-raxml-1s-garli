#! /usr/bin/env python3
# -*- Python -*-
# ======================================================================

import sys, os, socket, re, datetime, random, pprint, time as time_m
from pathlib import Path
import logging; module_logger = logging.getLogger(__name__)

# ======================================================================

ADMIN_EMAIL = "eu@antigenic-cartography.org"

BASE_SEQUENCES = {
    "h1": "SWITZERLAND/9772556/2013 SIAT2",
    "h3": "HAWAII/22/2012 MDCK",
    "bv": "VICTORIA/830/2013 MDCK2",
    "by": "CHRISTCHURCH/503/2013 MDCK1",
    }

# ======================================================================

class State:

    filename = Path("state.json")

    def __repr__(self):
        return pprint.pformat(vars(self))

    def load(self):
        from acmacs_base import json
        if self.filename.exists():
            for k, v in json.read(self.filename).items():
                setattr(self, k, v)
            self.source_fasta = Path(self.source_fasta)
        else:
            self.init()
        module_logger.info(f"{self}")

    def init(self):
        self.start = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def save(self):
        from acmacs_base import json
        json.write(path=self.filename, data=vars(self), indent=2, compact=True)

STATE = State()
RANDOM_GEN = random.SystemRandom()

class Error (Exception): pass

# ======================================================================

def main(args):
    global STATE
    setup(args)
    STATE.load()
    while True:
        if not STATE.source_fasta.exists():
            export_sequences()
        elif not getattr(STATE, "raxml_rough_time", None):
            if not getattr(STATE, "raxml_rough_job", None):
                raxml_rough_submit()
            else:
                raxml_wait(var_infix="rough")
        elif not getattr(STATE, "raxml_rough_best_tree", None):
            raxml_get_results(var_infix="rough")
        elif not getattr(STATE, "raxml_final_time", None):
            if not getattr(STATE, "raxml_final_job", None):
                raxml_final_submit()
            else:
                raxml_wait(var_infix="final")
        elif not getattr(STATE, "raxml_final_best_tree", None):
            raxml_get_results(var_infix="final")
        elif not getattr(STATE, "garli_time", None):
            if not getattr(STATE, "garli_job", None):
                garli_submit()
            else:
                garli_wait()
        elif not getattr(STATE, "garli_best_tree", None):
            garli_get_results()
        elif not getattr(STATE, "best_tree", None):
            find_best_tree()
        else:
            generate_results()
            module_logger.info(f"{STATE}")
            break
        STATE.save()
    email_success()

# ======================================================================

def export_sequences():
    global STATE
    module_logger.info(f"export_sequences")
    log_file = "log/seqdb-export.log"
    cmd = [
        os.path.expandvars("${ACMACSD_ROOT}/bin/seqdb-export"),
        "--flu", STATE.subtype,
        "--recent", STATE.number_of_sequences,
        "--hamming-distance-threshold", STATE.hamming_distance_threshold,
        "--tree-maker",
        "--base-seq", STATE.base_sequence,
        str(STATE.source_fasta)
    ]
    module_logger.info(f"exporting fasta: {STATE.source_fasta}\n  {cmd}\n  log: {log_file}")
    check_call(cmd, log_file)
    self.source_fasta = self.source_fasta.resolve()

# ----------------------------------------------------------------------

def raxml_rough_submit():
    global STATE, ADMIN_EMAIL
    module_logger.info(f"raxml_rough_submit")
    log_file = "log/raxml-rough.log"
    working_dir = Path(".").resolve()
    run_id = f"{working_dir.parent.name}-{working_dir.name}".replace(" ", "-")
    general_args = ["--stop-after-seconds", "1",
                    "-p", "$RANDOM_INTEGER(1, 2147483647)",
                    "-n", "s1.$(Process)",
                    "-N", "1000",
                    "-s", str(STATE.source_fasta),
                    "-m", "GTRGAMMAI",
                    "-e", "0.001",
                    "-o", STATE.source_fasta.open().readline().strip()[1:], # outgroup
                    "-c", "4",
                    "-f", "d",
                    "--silent",
                    "--no-seq-check",
                    "-D"]
    raxml_rough_dir = Path("raxml-rough")
    desc_filename, STATE.raxml_rough_condor_log = htcondor_prepare(
        program="/syn/bin/raxml",
        program_args = [general_args],
        description=f"raxml-rough {run_id} {STATE.raxml_runs}",
        queue=STATE.raxml_runs,
        cpus=2,                 # try to avoid hyper-threading
        current_dir=Path("raxml-rough"),
        priority=0,
        capture_stdout=True,
        email=ADMIN_EMAIL,
        notification="Error",
        machines=STATE.machines
        )
    STATE.raxml_rough_job = htcondor_submit(desc_filename)
    STATE.raxml_rough_started = time_m.time()

# ----------------------------------------------------------------------

def raxml_final_submit():
    global STATE, ADMIN_EMAIL
    module_logger.info(f"raxml_final_submit")
    log_file = "log/raxml-final.log"
    working_dir = Path(".").resolve()
    run_id = f"{working_dir.parent.name}-{working_dir.name}".replace(" ", "-")
    general_args = ["-t", STATE.raxml_rough_best_tree,
                    "-T", "16",
                    "-n", "final.$(Process)",
                    "-N", "1",
                    "-s", str(STATE.source_fasta),
                    "-m", "GTRGAMMAI",
                    "-e", "0.001",
                    "-o", STATE.source_fasta.open().readline().strip()[1:], # outgroup
                    "-c", "4",
                    "-f", "d",
                    "--silent",
                    "--no-seq-check",
                    "-D"]
    raxml_final_dir = Path("raxml-final")
    desc_filename, STATE.raxml_final_condor_log = htcondor_prepare(
        program="/syn/bin/raxml-pthreads",
        program_args = [general_args],
        description=f"raxml-final {run_id} {STATE.raxml_runs}",
        queue=1,
        cpus=32,                 # try to avoid hyper-threading
        current_dir=Path("raxml-final"),
        priority=1,
        capture_stdout=True,
        email=ADMIN_EMAIL,
        notification="Error",
        machines=STATE.machines
        )
    STATE.raxml_final_job = htcondor_submit(desc_filename)
    STATE.raxml_final_started = time_m.time()

# ----------------------------------------------------------------------

def garli_submit():
    # env OMP_NUM_THREADS=16 /syn/bin/garli garli.conf
    # /syn/eu/ac/results/signature-pages/2019-0411-h3-4k-s1-condor/garli.conf
    global STATE, ADMIN_EMAIL
    module_logger.info(f"garli_submit")
    log_file = "log/garli.log"
    working_dir = Path(".").resolve()
    run_id = f"{working_dir.parent.name}-{working_dir.name}".replace(" ", "-")
    garli_dir = Path("garli")
    garli_dir.mkdir(parents=True, exist_ok=True)
    garli_dir.joinpath("garli.conf").open("w").write("""
[general]
randseed = -1
datafname = {STATE.source_fasta}
streefname = {STATE.raxml_best_tree}
ofprefix = s1
constraintfile = none
attachmentspertaxon = 1000000
availablememory = 8000
logevery = 1000
writecheckpoints = 0
restart = 0
saveevery = 1000
refinestart = 1
outputcurrentbesttopology = 0
outputeachbettertopology = 0
enforcetermconditions = 1
genthreshfortopoterm = 20000
scorethreshforterm = 0.05
significanttopochange = 0.01
outputphyliptree = 1
outputmostlyuselessfiles = 0
outgroup = 1
resampleproportion = 1.0
inferinternalstateprobs = 0
outputsitelikelihoods = 0
optimizeinputonly = 0
collapsebranches = 1
searchreps = 1
bootstrapreps = 0
datatype=nucleotide
ratematrix = 6rate
statefrequencies = estimate
ratehetmodel = gamma
numratecats = 4
invariantsites = estimate
[master]
stoptime = {STATE.garli_stop_time}
nindivs = 4
holdover = 1
selectionintensity = .5
holdoverpenalty = 0
stopgen = 1000000
startoptprec = 0.5
minoptprec = 0.01
numberofprecreductions = 20
treerejectionthreshold = 50.0
topoweight = 1.0
modweight = 0.05
brlenweight = 0.2
randnniweight = 0.1
randsprweight = 0.3
limsprweight =  0.6
intervallength = 100
intervalstostore = 5
limsprrange = 6
meanbrlenmuts = 5
gammashapebrlen = 1000
gammashapemodel = 1000
uniqueswapbias = 0.1
distanceswapbias = 1.0
""")
    desc_filename, STATE.garli_condor_log = htcondor_prepare(
        program="/syn/bin/garli",
        program_args = ["garli.conf"],
        description=f"garli {run_id} {STATE.garli_runs}",
        queue=STATE.garli_runs,
        cpus=2,                 # try to avoid hyper-threading
        current_dir=Path("garli"),
        priority=2,
        capture_stdout=True,
        email=ADMIN_EMAIL,
        notification="Error",
        machines=STATE.machines
        )
    STATE.garli_job = htcondor_submit(desc_filename)
    STATE.garli_started = time_m.time()

# ----------------------------------------------------------------------

def raxml_wait(var_infix):
    import subprocess
    module_logger.info(f"raxml_wait {var_infix}")
    output = subprocess.run(["condor_wait", getattr(STATE, f"raxml_{var_infix}_condor_log")], env={"LD_LIBRARY_PATH": ""}, check=False, stdout=subprocess.PIPE).stdout.decode("utf-8") # ignore exit code, condor_wait exits with 1 on timeout
    if "All jobs done." in output:
        runtime = time_m.time() - getattr(STATE, f"raxml_{var_infix}_started")
        setattr(STATE, f"raxml_{var_infix}_time", runtime)
        module_logger.info(f"raxml {var_infix} jobs completed in {datetime.timedelta(seconds=runtime)}")
    elif "Time expired." in output:
        status = "timeout"
    else:
        status = "unknown"
        module_logger.warning('Unrecognized condor_wait output:\n' + output)

# ----------------------------------------------------------------------

def garli_wait(var_infix):
    import subprocess
    module_logger.info(f"garli_wait")
    output = subprocess.run(["condor_wait", getattr(STATE, f"garli_condor_log")], env={"LD_LIBRARY_PATH": ""}, check=False, stdout=subprocess.PIPE).stdout.decode("utf-8") # ignore exit code, condor_wait exits with 1 on timeout
    if "All jobs done." in output:
        runtime = time_m.time() - STATE.garli_started
        setattr(STATE, f"garli_time", runtime)
        module_logger.info(f"garli jobs completed in {datetime.timedelta(seconds=runtime)}")
    elif "Time expired." in output:
        status = "timeout"
    else:
        status = "unknown"
        module_logger.warning('Unrecognized condor_wait output:\n' + output)

# ----------------------------------------------------------------------

sInfoBestScore = re.compile(r"Final GAMMA-based Score of best tree -([\d\.]+)", re.I)
sInfoExecutionTime = re.compile(r"Overall execution time: ([\d\.]+) secs ", re.I)

def raxml_get_results(var_infix):
    module_logger.info(f"raxml_get_results {var_infix}")
    longest_time = None
    best_score = None
    best_tree = None
    for info_file in Path(f"raxml-{var_infix}").glob("RAxML_info.*"):
        info_data = info_file.open().read()
        m_score = sInfoBestScore.search(info_data)
        if m_score:
            score = float(m_score.group(1))
            if best_score is None or score < best_score:
                best_score = score
                best_tree = Path(f"raxml-{var_infix}", info_file.name.replace("_info", "_bestTree")).resolve()
        else:
            module_logger.warning(f"raxml-{var_infix}: cannot extract best score from {info_file}")
        m_time = sInfoExecutionTime.search(info_data)
        if m_time:
            runtime = float(m_time.group(1))
            if longest_time is None or runtime > longest_time:
                longest_time = runtime
    if longest_time is None:
        raise Error(f"raxml_get_results {var_infix}: no longest_time")
    setattr(STATE, f"raxml_{var_infix}_longest_time", longest_time)
    if best_score is None or best_tree is None:
        raise Error(f"raxml_get_results {var_infix}: no best_tree")
    setattr(STATE, f"raxml_{var_infix}_best_score", best_score)
    setattr(STATE, f"raxml_{var_infix}_best_tree", str(best_tree))
    STATE.raxml_best_score = str(best_score)
    STATE.raxml_best_tree = str(best_tree)
    module_logger.info(f"raxml-{var_infix} best tree: {best_score} {best_tree}")
    module_logger.info(f"raxml-{var_infix} longest run time: {datetime.timedelta(seconds=longest_time)}")

# ----------------------------------------------------------------------

def find_best_tree():
    if getattr(STATE, "garli_best_tree", None):
        STATE.best_tree = STATE.garli_best_tree
    else:
        STATE.best_tree = STATE.raxml_best_tree

# ----------------------------------------------------------------------

def generate_results():
    import subprocess
    subprocess.check_call(f"tree-newick-to-json <'{STATE.best_tree}' | xz -9e >tree.json.xz", shell=True)
    check_call(["sigp", "tree.json.xz", "tree.pdf", "--init-settings", "tree.settings.json"], "log/sigp.tree.log")

# ======================================================================

def setup(args):
    if socket.gethostname() != "i19":
        raise Error("The script must be run on i19")
    if not os.getenv("ACMACSD_ROOT") or not Path(os.getenv("ACMACSD_ROOT"), "data", "hidb5.h1.json.xz"):
        raise Error("ACMACSD_ROOT not set or no hidb in $ACMACSD_ROOT/data")
    else:
        ACMACSD_ROOT = Path(os.getenv("ACMACSD_ROOT")).resolve()
    sys.path[1:1] = [os.getenv("ACMACSD_ROOT") + "/py"]

    STATE.subtype = args.subtype.lower()
    if STATE.subtype not in ["h1", "h3", "bv", "by"]:
        raise Error(f"Invalid subtype: {STATE.subtype}")

    STATE.machines = [args.machine] if args.machine else None
    STATE.raxml_runs = args.raxml_runs
    STATE.garli_runs = args.garli_runs
    STATE.source_fasta = Path("source.fas")
    STATE.number_of_sequences = args.number_of_sequences
    STATE.hamming_distance_threshold = args.hamming_distance_threshold
    STATE.base_sequence = args.base_sequence
    if STATE.base_sequence is None:
        global BASE_SEQUENCES
        STATE.base_sequence = BASE_SEQUENCES[STATE.subtype]
    STATE.garli_stop_time = 3600

    if not STATE.filename.exists():
        root_dir = Path("/syn/eu/ac/results/signature-pages", datetime.date.today().strftime("%Y-%m%d"), STATE.subtype)
        root_dir.mkdir(parents=True, exist_ok=True)
        os.chdir(str(root_dir))

    Path("log").mkdir(parents=True, exist_ok=True)
    logging_format = "%(levelname)s %(asctime)s: %(message)s"
    logging.basicConfig(filename="log/main.log", level=args.loglevel, format=logging_format, datefmt="%Y-%m-%d %H:%M:%S")
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(logging.Formatter(logging_format))
    logging.getLogger().addHandler(stream_handler)

    module_logger.info(f"{os.getcwd()}")

# ======================================================================

def check_call(cmd, log_file):
    import subprocess
    module_logger.info(str(cmd))
    subprocess.check_call([str(field) for field in cmd], stdout=Path(log_file).open("a"), stderr=subprocess.STDOUT)

# ----------------------------------------------------------------------

def random_seed():
    global RANDOM_GEN
    return RANDOM_GEN.randint(1, 0xFFFFFFF)   # note max for garli is 0x7ffffffe

# ----------------------------------------------------------------------

def htcondor_prepare(program, program_args :list, description :str, current_dir :Path, queue=1, cpus=1, request_memory=None, capture_stdout=False, email=None, notification="Error", machines :list = None, priority :int = 0):
    current_dir.mkdir(parents=True, exist_ok=True)
    current_dir = current_dir.resolve()
    current_dir.chmod(0o777)        # to allow remote processes runinnig under user nobody to write files
    condor_log = current_dir.joinpath("condor.log")
    desc = [
        ["universe", "vanilla"],
        ["executable", str(Path(program).resolve())],
        ["priority", str(priority)],
        ["should_transfer_files", "NO"],
        ["notify_user", email or ""],
        ["notification", notification if email else "Never"],
        ["Requirements", "({})".format(" || ".join(f'machine == "{machine}"' for machine in machines)) if machines else None],
        ["request_memory", str(request_memory) if request_memory is not None else "2000"],
        ["request_cpus", str(cpus)],
        ["initialdir", str(current_dir)],
        ["log", str(condor_log)],
        ["description", "{} {}".format(description, current_dir)],
        [""],
        ]
    stderr_files = [current_dir.joinpath("output", f"{no:04d}.stderr") for no, args in enumerate(program_args)]
    for f in stderr_files:
        f.parent.mkdir(parents=True, exist_ok=True)
        f.touch()
        f.chmod(0o777)
    if capture_stdout:
        stdout_files = [current_dir.joinpath("output", f"{no:04d}.stdout") for no, args in enumerate(program_args)]
        for f in stdout_files:
            f.touch()
            f.chmod(0o777)
    else:
        stdout_files = [None] * len(program_args)
    for no, args in enumerate(program_args):
        desc.extend([
            ["arguments", " ".join(str(a) for a in args)],
            ["error", stderr_files[no] and str(stderr_files[no])],
            ["output", stdout_files[no] and str(stdout_files[no])],
            [f"queue {queue}"],
            [""],
            ])
    desc_s = "\n".join((" = ".join(e) if len(e) == 2 else e[0]) for e in desc if len(e) != 2 or e[1])
    desc_filename = Path(current_dir, "condor.desc")
    with desc_filename.open("w") as f:
        f.write(desc_s)
    desc_filename = desc_filename.resolve()
    module_logger.info('HTCondor desc {}'.format(desc_filename))
    return desc_filename, condor_log

# ----------------------------------------------------------------------

sReCondorProc = re.compile(r'\*\*\s+Proc\s+(\d+)\.(\d+):')

def htcondor_submit(desc_filename):
    import subprocess, collections
    output = subprocess.check_output(["condor_submit", "-verbose", str(desc_filename)], env={"LD_LIBRARY_PATH": ""}).decode("utf-8")
    cluster = collections.defaultdict(int)
    for line in output.splitlines():
        m1 = sReCondorProc.match(line)
        if m1:
            cluster[m1.group(1)] += 1
    if not cluster:
        logging.error(output)
        raise RuntimeError(f"cluster id not found in the submission results {cluster}")
    return dict(cluster)

# ----------------------------------------------------------------------

EMACS_PREFIX = f"/scp:{socket.gethostname()}:"

def email_error(err):
    from acmacs_base.email import send
    ROOT_DIR = Path(".").resolve()
    subject = f"FAILED: {socket.gethostname()} {sys.argv}"
    url = "https://notebooks.antigenic-cartography.org/eu/" + str(ROOT_DIR).replace("/syn/eu/ac/", "")
    url_commont = "https://notebooks.antigenic-cartography.org/eu/" + str(ROOT_DIR.parent).replace("/syn/eu/ac/", "")
    send(to=ADMIN_EMAIL, subject=subject, body=f"{subject}\n{url}\n{url_commont}\n{EMACS_PREFIX}{ROOT_DIR}\n\n{err}")

def email_success():
    from acmacs_base.email import send
    ROOT_DIR = Path(".").resolve()
    subject = f"completed: {socket.gethostname()} {sys.argv}"
    url = "https://notebooks.antigenic-cartography.org/eu/" + str(ROOT_DIR).replace("/syn/eu/ac/", "")
    url_commont = "https://notebooks.antigenic-cartography.org/eu/" + str(ROOT_DIR.parent).replace("/syn/eu/ac/", "")
    send(to=ADMIN_EMAIL, subject=subject, body=f"{subject}\n{url}\n{url_commont}\n{EMACS_PREFIX}{ROOT_DIR}")

# ======================================================================

import argparse, traceback

try:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('subtype', help="h1 h3 bv by")
    parser.add_argument('-m', '--machine', dest="machine", default=None, help="i22, o16, o17")
    parser.add_argument('--raxml', dest="raxml_runs", type=int, default=128)
    parser.add_argument('--garli', dest="garli_runs", type=int, default=1)
    parser.add_argument('--number-of-sequences', dest="number_of_sequences", default=4000, type=int)
    parser.add_argument('--hamming-distance-threshold', dest="hamming_distance_threshold", default=160, type=int)
    parser.add_argument('--base-seq', dest="base_sequence", default=None, help="regex, use seqdb-list --re <name> to check possible names. It must select just one sequence.")
    parser.add_argument('-d', '--debug', action='store_const', dest='loglevel', const=logging.DEBUG, default=logging.INFO, help='Enable debugging output.')

    args = parser.parse_args()
    exit_code = main(args)
except Error as err:
    logging.error(str(err))
    email_error(f"{err}\n{traceback.format_exc()}")
    STATE.error = str(err)
    STATE.save()
    exit_code = 2
except Exception as err:
    logging.error('{}\n{}'.format(err, traceback.format_exc()))
    email_error(f"{err}\n{traceback.format_exc()}")
    STATE.error = str(err)
    STATE.save()
    exit_code = 1
exit(exit_code)

# ======================================================================
### Local Variables:
### eval: (if (fboundp 'eu-rename-buffer) (eu-rename-buffer))
### End:
