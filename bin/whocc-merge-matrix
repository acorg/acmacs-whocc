#! /usr/bin/env python3
# -*- Python -*-

"""Makes merges of sets of recent tables (recent N tables, recent N*2
tables, etc.), relaxes each merge and runs grid test, then generates
web page showing all the results in the matrix form. Similar to
https://notebooks.antigenic-cartography.org/eu/results/cdc/2018-1114-h1pdm-spb-61-2105-for-david-wentworth/matrix/
(/scp:i19:/syn/eu/ac/results/cdc/2018-1114-h1pdm-spb-61-2105-for-david-wentworth/README)
"""

import sys, re, pprint, time, traceback, subprocess, datetime
if sys.version_info.major != 3: raise RuntimeError("Run script with python3")
from pathlib import Path
import logging; module_logger = logging.getLogger(__name__)

# ----------------------------------------------------------------------

WORKING_DIR = None

def main(args):
    global WORKING_DIR
    WORKING_DIR = Path(args.working_dir).resolve()
    sets = get_sets(args)
    merges = [make_merge(source_set) for source_set in sets]
    merges_optimized = relax_merges(merges, args)
    merges_after_grid = grid_merges(merges_optimized, args)
    state = make_state(merges_after_grid, args)
    make_maps(state, args)
    pprint.pprint(state)

# ----------------------------------------------------------------------

sDateExtractor = re.compile(r"-((?:19|20)\d\d[01]\d[0-3]\d)")

def make_merge(source_set):
    m1 = sDateExtractor.search(source_set[0])
    m2 = sDateExtractor.search(source_set[-1])
    if not m1 or not m2:
        raise RuntimeError(f"cannot extract dates from {source_set[0]} or {source_set[-1]}")
    date_range = f"{m1.group(1)}-{m2.group(1)}"
    merge_name = WORKING_DIR.joinpath(f"{date_range}.merge.ace")
    if not merge_name.exists():
        log_file = WORKING_DIR.joinpath(f"{date_range}.merge.log")
        check_call(["chart-merge", "-o", merge_name] + source_set, log_file=log_file)
        print(merge_name)
    else:
        print(merge_name, " -- already exists")
    return merge_name

# ----------------------------------------------------------------------

def relax_merges(merges, args):
    result = []
    for merge in merges:
        merge_optimized = WORKING_DIR.joinpath(Path(merge.stem).stem + ".opt.ace")
        if not merge_optimized.exists():
            check_call(["chart-relax", "-n", args.number_of_optimizations, "-d", args.number_of_dimensions, "-m", args.minimum_column_basis, "--rough",
                        "--keep-projections", args.projections_to_keep, merge, merge_optimized])
            check_call(["chart-relax-existing", merge_optimized, merge_optimized])
        result.append(merge_optimized)
    return result

# ----------------------------------------------------------------------

def grid_merges(merges, args):
    result = []
    for merge in merges:
        merge_grid = WORKING_DIR.joinpath(Path(merge.stem).stem + ".grid.ace")
        if not merge_grid.exists():
            check_call(["chart-grid-test", "--relax", merge, merge_grid])
            if args.reorient_to:
                check_call(["chart-reorient", "-p", "-1", args.reorient_to, merge_grid, merge_grid])
        result.append(merge_grid)
    return result

# ----------------------------------------------------------------------

def make_state(merges, args):
    state = {"charts": [chart_info(fn) for fn in merges]}
    state["max_grid_results"] = max(ci["grid_results"] for ci in state["charts"])
    return state

# ----------------------------------------------------------------------

def make_maps(state, args):
    state["row_titles"] = ["-".join(chart["dates"]) for chart in state["charts"]]
    state["column_titles"] = [f"grid-{gr+1}" for gr in range(state["max_grid_results"])] + [str(p+1) for p in range(5)]
    state["grid"] = [make_row_maps(chart, state["max_grid_results"]) for chart in state["charts"]]

# ----------------------------------------------------------------------

def make_row_maps(chart, max_grid_results):
    result = []
    projection = 0
    for gr in range(max_grid_results):
        if gr < chart["grid_results"]:
            result.append(f"gr-{gr}")
            projection += 1
        else:
            result.append(None)
    for pr in range(5):
        result.append(f"p-{projection}")
        projection += 1
    return result

# ----------------------------------------------------------------------

sReDates = re.compile(r"((?:19|20)\d\d[01]\d[0-3]\d)(?:\.\d+)?-((?:19|20)\d\d[01]\d[0-3]\d)")
sRePrejections = re.compile(r"^Projections:\s*(\d+)")

def chart_info(merge):
    info = {"path": merge, "grid_results": 0}
    data = subprocess.check_output(["chart-info", str(merge)]).decode("utf-8").split("\n")
    for line in data:
        if not info.get("dates"):
            m_d = sReDates.search(line)
            if m_d:
                info["dates"] = [m_d.group(1), m_d.group(2)]
        m_p = sRePrejections.match(line)
        if m_p:
            info["projections"] = int(m_p.group(1))
        elif info.get("projections") and "<grid-test" in line:
            info["grid_results"] += 1
    return info

# ----------------------------------------------------------------------

def get_sets(args):
    all_tables = sorted(args.pattern)
    set_sizes = [set_size for set_size in range(args.step, len(all_tables), args.step)]
    if set_sizes[-1] < len(all_tables):
        set_sizes.append(len(all_tables))
    sets = [all_tables[-set_size:] for set_size in set_sizes]
    # pprint.pprint(sets, width=200)
    return sets

# ----------------------------------------------------------------------

def check_call(cmd, log_file=None):
    if len(cmd) < 16:
        module_logger.info(" ".join(repr(str(field)) for field in cmd))
    else:
        module_logger.info(" ".join(str(field) for field in cmd) + " ...")
    stdout = log_file.open("a") if log_file else None
    start = datetime.datetime.utcnow()
    subprocess.check_call([str(field) for field in cmd], stdout=stdout, stderr=subprocess.STDOUT)
    module_logger.info(f"{cmd[0]}: <{datetime.datetime.utcnow() - start}>")

# ----------------------------------------------------------------------

try:
    import argparse
    parser = argparse.ArgumentParser(description=__doc__)

    parser.add_argument("--debug", action="store_const", dest="loglevel", const=logging.DEBUG, default=logging.INFO, help="Enable debugging output.")

    parser.add_argument("--step", type=int, dest="step", default=20, help="Number of tables to increment by.")
    parser.add_argument("-n", "--number-of-optimizations", type=int, dest="number_of_optimizations", default=1000)
    parser.add_argument("-d", "--number-of-dimensions", type=int, dest="number_of_dimensions", default=2)
    parser.add_argument("-m", "--minimum-column-basis", dest="minimum_column_basis", default="none")
    parser.add_argument("-k", "--projections-to-keep", type=int, dest="projections_to_keep", default=10)
    parser.add_argument("-r", "--reorient", dest="reorient_to", default=None)
    parser.add_argument("--working-dir", dest="working_dir", default=".")

    parser.add_argument("pattern", nargs="*")

    args = parser.parse_args()
    logging.basicConfig(level=args.loglevel, format="%(levelname)s %(asctime)s: %(message)s")
    exit_code = main(args)
except Exception as err:
    logging.error(f"{err}\n{traceback.format_exc()}")
    exit_code = 1
exit(exit_code)


# ======================================================================
### Local Variables:
### eval: (if (fboundp 'eu-rename-buffer) (eu-rename-buffer))
### End:
